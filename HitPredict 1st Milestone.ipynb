{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HitPredict 1st Milestone\n",
    "## Data Collection, Visualisation and Feature Engineering\n",
    "\n",
    "Hit predict will predict the popularity of a song based on some of its musical properties. We used the Spotify DB datasert from kaggle, which contains numerous rows of features of over 230.000 tracks. It was assembled using Spotify's API.\n",
    "\n",
    "As always we started with importing the libraries that we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database is in .csv format, we used Pandas' read_csv() function to import it to Python. We visualize the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SpotifyFeatures.csv')\n",
    "print(data.head())\n",
    "print(data.describe())\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First and foremost let's check for any 0 data points that we might need to replace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.isnull(data).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately there are none, let's move on with some of the feature engineering that we have done. \n",
    "\n",
    "Most values are numerical and need no preprocessing. We do have to convert however some text based rows into numbers which can be fed to the network afterwards.\n",
    "Such rows are Key, Mode and Time Signature all of which will be replaced with integers 1 through the number of unique types that the given row may contain. \n",
    "\n",
    "I was not familiar with most of these terms, below you will find short descriptions that helped me better understand them.\n",
    "Time signature: (also known as meter signature, metre signature, or measure signature) is a notational convention used in Western musical notation to specify how many beats (pulses) are contained in each measure (bar), and which note value is equivalent to a beat.\n",
    "Mode: In the theory of Western music, it is a type of musical scale coupled with a set of characteristic melodic behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key first\n",
    "\n",
    "list_of_keys = data['key'].unique()\n",
    "for i in range(len(list_of_keys)):\n",
    "    data.loc[data['key'] == list_of_keys[i], 'key'] = i\n",
    "data.sample(10)\n",
    "\n",
    "#mode second\n",
    "\n",
    "dataframe.loc[dataframe[\"mode\"] == 'Major', \"mode\"] = 1\n",
    "dataframe.loc[dataframe[\"mode\"] == 'Minor', \"mode\"] = 0\n",
    "dataframe.sample(10)\n",
    "\n",
    "#time signature last\n",
    "\n",
    "list_of_time_signatures = data['time_signature'].unique()\n",
    "for i in range(len(list_of_time_signatures)):\n",
    "    data.loc[data['time_signature'] == list_of_time_signatures[i], 'time_signature'] = i\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the outcome will be binary, we had to adjust the popularity label either to 1 or 0. This output may change in the project afterwards to a probability. We chose an arbitrary 25-75 split to do this. (Top 25% are considered popular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.loc[dataframe['popularity'] < 75, 'popularity'] = 0 \n",
    "dataframe.loc[dataframe['popularity'] >= 75, 'popularity'] = 1\n",
    "dataframe.loc[dataframe['popularity'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we select all the features, which will be fed to the network, and split the data into 60% training 20% validation and 20% test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"acousticness\", \"danceability\", \"duration_ms\", \"energy\", \"instrumentalness\", \"key\", \"liveness\", \n",
    "            \"mode\", \"speechiness\", \"tempo\", \"time_signature\", \"valence\"]\n",
    "\n",
    "train, validate, test = np.split(data.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
