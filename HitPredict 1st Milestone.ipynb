{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HitPredict\n",
    "\n",
    "Hit predict will predict the popularity of a song based on some of its musical properties. We used the Spotify DB dataset from kaggle, which contains numerous rows of features of over 230.000 tracks. It was assembled using Spotify's API.\n",
    "\n",
    "As always we started with importing the libraries that we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database is in .csv format, we used Pandas' read_csv() function to import it to Python. We visualize the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Movie</td>\n",
       "      <td>Henri Salvador</td>\n",
       "      <td>C'est beau de faire un Show</td>\n",
       "      <td>0BRjO6ga9RKCKjfDqeFgWV</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.389</td>\n",
       "      <td>99373</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>C#</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>-1.828</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>166.969</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie</td>\n",
       "      <td>Martin &amp; les fées</td>\n",
       "      <td>Perdu d'avance (par Gad Elmaleh)</td>\n",
       "      <td>0BjC1NfoEOOusryehmNudP</td>\n",
       "      <td>1</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.590</td>\n",
       "      <td>137373</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.000</td>\n",
       "      <td>F#</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-5.559</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>174.003</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Movie</td>\n",
       "      <td>Joseph Williams</td>\n",
       "      <td>Don't Let Me Be Lonely Tonight</td>\n",
       "      <td>0CoSDzoNIKCRs124s9uTVy</td>\n",
       "      <td>3</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.663</td>\n",
       "      <td>170267</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.000</td>\n",
       "      <td>C</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>-13.879</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>99.488</td>\n",
       "      <td>5/4</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Movie</td>\n",
       "      <td>Henri Salvador</td>\n",
       "      <td>Dis-moi Monsieur Gordon Cooper</td>\n",
       "      <td>0Gc6TVm52BwZD07Ki6tIvf</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.240</td>\n",
       "      <td>152427</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>C#</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>-12.178</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>171.758</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Movie</td>\n",
       "      <td>Fabien Nataf</td>\n",
       "      <td>Ouverture</td>\n",
       "      <td>0IuslXpMROHdEPvSl1fTQK</td>\n",
       "      <td>4</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.331</td>\n",
       "      <td>82625</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.123</td>\n",
       "      <td>F</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>-21.150</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>140.576</td>\n",
       "      <td>4/4</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genre        artist_name                        track_name  \\\n",
       "0  Movie     Henri Salvador       C'est beau de faire un Show   \n",
       "1  Movie  Martin & les fées  Perdu d'avance (par Gad Elmaleh)   \n",
       "2  Movie    Joseph Williams    Don't Let Me Be Lonely Tonight   \n",
       "3  Movie     Henri Salvador    Dis-moi Monsieur Gordon Cooper   \n",
       "4  Movie       Fabien Nataf                         Ouverture   \n",
       "\n",
       "                 track_id  popularity  acousticness  danceability  \\\n",
       "0  0BRjO6ga9RKCKjfDqeFgWV           0         0.611         0.389   \n",
       "1  0BjC1NfoEOOusryehmNudP           1         0.246         0.590   \n",
       "2  0CoSDzoNIKCRs124s9uTVy           3         0.952         0.663   \n",
       "3  0Gc6TVm52BwZD07Ki6tIvf           0         0.703         0.240   \n",
       "4  0IuslXpMROHdEPvSl1fTQK           4         0.950         0.331   \n",
       "\n",
       "   duration_ms  energy  instrumentalness key  liveness  loudness   mode  \\\n",
       "0        99373   0.910             0.000  C#    0.3460    -1.828  Major   \n",
       "1       137373   0.737             0.000  F#    0.1510    -5.559  Minor   \n",
       "2       170267   0.131             0.000   C    0.1030   -13.879  Minor   \n",
       "3       152427   0.326             0.000  C#    0.0985   -12.178  Major   \n",
       "4        82625   0.225             0.123   F    0.2020   -21.150  Major   \n",
       "\n",
       "   speechiness    tempo time_signature  valence  \n",
       "0       0.0525  166.969            4/4    0.814  \n",
       "1       0.0868  174.003            4/4    0.816  \n",
       "2       0.0362   99.488            5/4    0.368  \n",
       "3       0.0395  171.758            4/4    0.227  \n",
       "4       0.0456  140.576            4/4    0.390  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('SpotifyFeatures.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track ID is not giving us any useful information so lets just get rid of it. As well as we need to remove the name of the track and the name of the artist from the dataset because proccessing them would just confuse the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['track_id']\n",
    "del data['artist_name']\n",
    "del data['track_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>2.327250e+05</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "      <td>232725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.127502</td>\n",
       "      <td>0.368560</td>\n",
       "      <td>0.554364</td>\n",
       "      <td>2.351223e+05</td>\n",
       "      <td>0.570958</td>\n",
       "      <td>0.148301</td>\n",
       "      <td>0.215009</td>\n",
       "      <td>-9.569885</td>\n",
       "      <td>0.120765</td>\n",
       "      <td>117.666585</td>\n",
       "      <td>0.454917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.189948</td>\n",
       "      <td>0.354768</td>\n",
       "      <td>0.185608</td>\n",
       "      <td>1.189359e+05</td>\n",
       "      <td>0.263456</td>\n",
       "      <td>0.302768</td>\n",
       "      <td>0.198273</td>\n",
       "      <td>5.998204</td>\n",
       "      <td>0.185518</td>\n",
       "      <td>30.898907</td>\n",
       "      <td>0.260065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>1.538700e+04</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>-52.457000</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>30.379000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>1.828570e+05</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>-11.771000</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>92.959000</td>\n",
       "      <td>0.237000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>2.204270e+05</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.128000</td>\n",
       "      <td>-7.762000</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>115.778000</td>\n",
       "      <td>0.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>2.657680e+05</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>-5.501000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>139.054000</td>\n",
       "      <td>0.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.989000</td>\n",
       "      <td>5.552917e+06</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.744000</td>\n",
       "      <td>0.967000</td>\n",
       "      <td>242.903000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          popularity   acousticness   danceability   duration_ms  \\\n",
       "count  232725.000000  232725.000000  232725.000000  2.327250e+05   \n",
       "mean       41.127502       0.368560       0.554364  2.351223e+05   \n",
       "std        18.189948       0.354768       0.185608  1.189359e+05   \n",
       "min         0.000000       0.000000       0.056900  1.538700e+04   \n",
       "25%        29.000000       0.037600       0.435000  1.828570e+05   \n",
       "50%        43.000000       0.232000       0.571000  2.204270e+05   \n",
       "75%        55.000000       0.722000       0.692000  2.657680e+05   \n",
       "max       100.000000       0.996000       0.989000  5.552917e+06   \n",
       "\n",
       "              energy  instrumentalness       liveness       loudness  \\\n",
       "count  232725.000000     232725.000000  232725.000000  232725.000000   \n",
       "mean        0.570958          0.148301       0.215009      -9.569885   \n",
       "std         0.263456          0.302768       0.198273       5.998204   \n",
       "min         0.000020          0.000000       0.009670     -52.457000   \n",
       "25%         0.385000          0.000000       0.097400     -11.771000   \n",
       "50%         0.605000          0.000044       0.128000      -7.762000   \n",
       "75%         0.787000          0.035800       0.264000      -5.501000   \n",
       "max         0.999000          0.999000       1.000000       3.744000   \n",
       "\n",
       "         speechiness          tempo        valence  \n",
       "count  232725.000000  232725.000000  232725.000000  \n",
       "mean        0.120765     117.666585       0.454917  \n",
       "std         0.185518      30.898907       0.260065  \n",
       "min         0.022200      30.379000       0.000000  \n",
       "25%         0.036700      92.959000       0.237000  \n",
       "50%         0.050100     115.778000       0.444000  \n",
       "75%         0.105000     139.054000       0.660000  \n",
       "max         0.967000     242.903000       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First and foremost let's check for any 0 data points that we might need to replace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre               0\n",
      "popularity          0\n",
      "acousticness        0\n",
      "danceability        0\n",
      "duration_ms         0\n",
      "energy              0\n",
      "instrumentalness    0\n",
      "key                 0\n",
      "liveness            0\n",
      "loudness            0\n",
      "mode                0\n",
      "speechiness         0\n",
      "tempo               0\n",
      "time_signature      0\n",
      "valence             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.isnull(data).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately there are none, let's move on with some of the feature engineering that we have done. \n",
    "\n",
    "Most values are numerical and need no preprocessing. We do have to convert however some text based rows into numbers which can be fed to the network afterwards.\n",
    "Such rows are Key, Mode and Time Signature all of which will be replaced with integers 1 through the number of unique types that the given row may contain. \n",
    "\n",
    "I was not familiar with most of these terms, below you will find short descriptions that helped me better understand them.\n",
    "Time signature: (also known as meter signature, metre signature, or measure signature) is a notational convention used in Western musical notation to specify how many beats (pulses) are contained in each measure (bar), and which note value is equivalent to a beat.\n",
    "Mode: In the theory of Western music, it is a type of musical scale coupled with a set of characteristic melodic behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessing genre. number of unique fields: 27\n",
      "['Movie' 'R&B' 'A Capella' 'Alternative' 'Country' 'Dance' 'Electronic'\n",
      " 'Anime' 'Folk' 'Blues' 'Opera' 'Hip-Hop' \"Children's Music\"\n",
      " 'Children’s Music' 'Rap' 'Indie' 'Classical' 'Pop' 'Reggae' 'Reggaeton'\n",
      " 'Jazz' 'Rock' 'Ska' 'Comedy' 'Soul' 'Soundtrack' 'World']\n",
      "Number of occurance of each unique value:\n",
      "genre\n",
      "A Capella            119\n",
      "Alternative         9263\n",
      "Anime               8936\n",
      "Blues               9023\n",
      "Children's Music    5403\n",
      "Children’s Music    9353\n",
      "Classical           9256\n",
      "Comedy              9681\n",
      "Country             8664\n",
      "Dance               8701\n",
      "Electronic          9377\n",
      "Folk                9299\n",
      "Hip-Hop             9295\n",
      "Indie               9543\n",
      "Jazz                9441\n",
      "Movie               7806\n",
      "Opera               8280\n",
      "Pop                 9386\n",
      "R&B                 8992\n",
      "Rap                 9232\n",
      "Reggae              8771\n",
      "Reggaeton           8927\n",
      "Rock                9272\n",
      "Ska                 8874\n",
      "Soul                9089\n",
      "Soundtrack          9646\n",
      "World               9096\n",
      "Name: popularity, dtype: int64\n",
      "Adding A Capella category to the 'OTHER' category.\n",
      "Final number of unique fields:\n",
      "genre\n",
      "Alternative         9263\n",
      "Anime               8936\n",
      "Blues               9023\n",
      "Children's Music    5403\n",
      "Children’s Music    9353\n",
      "Classical           9256\n",
      "Comedy              9681\n",
      "Country             8664\n",
      "Dance               8701\n",
      "Electronic          9377\n",
      "Folk                9299\n",
      "Hip-Hop             9295\n",
      "Indie               9543\n",
      "Jazz                9441\n",
      "Movie               7806\n",
      "OTHER                119\n",
      "Opera               8280\n",
      "Pop                 9386\n",
      "R&B                 8992\n",
      "Rap                 9232\n",
      "Reggae              8771\n",
      "Reggaeton           8927\n",
      "Rock                9272\n",
      "Ska                 8874\n",
      "Soul                9089\n",
      "Soundtrack          9646\n",
      "World               9096\n",
      "Name: popularity, dtype: int64\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'artist_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'artist_name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-36ac813418cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Proccessing %s. number of unique fields: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'artist_name'"
     ]
    }
   ],
   "source": [
    "categorical_features = [\"genre\",\"artist_name\",\"time_signature\",\"key\",\"mode\"]\n",
    "n_items = len(data)\n",
    "for feat in categorical_features:\n",
    "    print(\"Proccessing %s. number of unique fields: %d\" % (feat, data[feat].nunique()))\n",
    "    if data[feat].nunique()<50:\n",
    "        print(data[feat].unique())\n",
    "        print(\"Number of occurance of each unique value:\")\n",
    "        print(data.groupby(feat).count().iloc[:,0])\n",
    "        for feat_value in data[feat].unique():\n",
    "            if (len(data[data[feat]==feat_value]) / n_items <= 0.02):\n",
    "                print(\"Adding %s category to the 'OTHER' category.\" % feat_value)\n",
    "                data[feat] = data[feat].apply(lambda x: \"OTHER\" if x==feat_value else x, 1)\n",
    "                \n",
    "        print(\"Final number of unique fields:\")\n",
    "        print(data.groupby(feat).count().iloc[:,0]) \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are not too many possible values for these categorical features we can one-hot-encode them for more efficient learning, using pandas built-in function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>genre_Alternative</th>\n",
       "      <th>genre_Anime</th>\n",
       "      <th>genre_Blues</th>\n",
       "      <th>genre_Children's Music</th>\n",
       "      <th>genre_Children’s Music</th>\n",
       "      <th>genre_Classical</th>\n",
       "      <th>genre_Comedy</th>\n",
       "      <th>genre_Country</th>\n",
       "      <th>genre_Dance</th>\n",
       "      <th>genre_Electronic</th>\n",
       "      <th>genre_Folk</th>\n",
       "      <th>genre_Hip-Hop</th>\n",
       "      <th>genre_Indie</th>\n",
       "      <th>genre_Jazz</th>\n",
       "      <th>genre_Movie</th>\n",
       "      <th>genre_OTHER</th>\n",
       "      <th>genre_Opera</th>\n",
       "      <th>genre_Pop</th>\n",
       "      <th>genre_R&amp;B</th>\n",
       "      <th>genre_Rap</th>\n",
       "      <th>genre_Reggae</th>\n",
       "      <th>genre_Reggaeton</th>\n",
       "      <th>genre_Rock</th>\n",
       "      <th>genre_Ska</th>\n",
       "      <th>genre_Soul</th>\n",
       "      <th>genre_Soundtrack</th>\n",
       "      <th>genre_World</th>\n",
       "      <th>time_signature_0/4</th>\n",
       "      <th>time_signature_1/4</th>\n",
       "      <th>time_signature_3/4</th>\n",
       "      <th>time_signature_4/4</th>\n",
       "      <th>time_signature_5/4</th>\n",
       "      <th>key_A</th>\n",
       "      <th>key_A#</th>\n",
       "      <th>key_B</th>\n",
       "      <th>key_C</th>\n",
       "      <th>key_C#</th>\n",
       "      <th>key_D</th>\n",
       "      <th>key_D#</th>\n",
       "      <th>key_E</th>\n",
       "      <th>key_F</th>\n",
       "      <th>key_F#</th>\n",
       "      <th>key_G</th>\n",
       "      <th>key_G#</th>\n",
       "      <th>mode_Major</th>\n",
       "      <th>mode_Minor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103869</th>\n",
       "      <td>51</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.722</td>\n",
       "      <td>237920</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>-3.227</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>117.693</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24247</th>\n",
       "      <td>39</td>\n",
       "      <td>0.006630</td>\n",
       "      <td>0.703</td>\n",
       "      <td>235333</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>-6.435</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>90.048</td>\n",
       "      <td>0.3870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181919</th>\n",
       "      <td>43</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.678</td>\n",
       "      <td>182893</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>-14.695</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>119.889</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152944</th>\n",
       "      <td>69</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.530</td>\n",
       "      <td>203453</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>-5.516</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>109.827</td>\n",
       "      <td>0.6960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153187</th>\n",
       "      <td>54</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.398</td>\n",
       "      <td>232187</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>-3.232</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>111.676</td>\n",
       "      <td>0.6110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36711</th>\n",
       "      <td>28</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.601</td>\n",
       "      <td>260569</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>-8.077</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>127.997</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124296</th>\n",
       "      <td>0</td>\n",
       "      <td>0.939000</td>\n",
       "      <td>0.499</td>\n",
       "      <td>102107</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>-24.238</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>60.424</td>\n",
       "      <td>0.4030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>39</td>\n",
       "      <td>0.346000</td>\n",
       "      <td>0.476</td>\n",
       "      <td>225952</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>-6.434</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>133.088</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104698</th>\n",
       "      <td>22</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.389</td>\n",
       "      <td>105507</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>-23.298</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>76.932</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23503</th>\n",
       "      <td>42</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.378</td>\n",
       "      <td>191294</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.2190</td>\n",
       "      <td>-2.102</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>170.653</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        popularity  acousticness  danceability  duration_ms  energy  \\\n",
       "103869          51      0.050500         0.722       237920   0.828   \n",
       "24247           39      0.006630         0.703       235333   0.872   \n",
       "181919          43      0.797000         0.678       182893   0.312   \n",
       "152944          69      0.104000         0.530       203453   0.707   \n",
       "153187          54      0.000945         0.398       232187   0.967   \n",
       "36711           28      0.002920         0.601       260569   0.654   \n",
       "124296           0      0.939000         0.499       102107   0.146   \n",
       "4637            39      0.346000         0.476       225952   0.447   \n",
       "104698          22      0.988000         0.389       105507   0.196   \n",
       "23503           42      0.000586         0.378       191294   0.933   \n",
       "\n",
       "        instrumentalness  liveness  loudness  speechiness    tempo  valence  \\\n",
       "103869          0.000000    0.1140    -3.227       0.1900  117.693   0.2750   \n",
       "24247           0.175000    0.1180    -6.435       0.1500   90.048   0.3870   \n",
       "181919          0.000000    0.1150   -14.695       0.0392  119.889   0.9530   \n",
       "152944          0.000000    0.1050    -5.516       0.2030  109.827   0.6960   \n",
       "153187          0.000006    0.1800    -3.232       0.0611  111.676   0.6110   \n",
       "36711           0.754000    0.1100    -8.077       0.0332  127.997   0.0811   \n",
       "124296          0.000003    0.4950   -24.238       0.1300   60.424   0.4030   \n",
       "4637            0.000028    0.0875    -6.434       0.0292  133.088   0.3240   \n",
       "104698          0.910000    0.2090   -23.298       0.0492   76.932   0.4420   \n",
       "23503           0.013200    0.2190    -2.102       0.3140  170.653   0.3460   \n",
       "\n",
       "        genre_Alternative  genre_Anime  genre_Blues  genre_Children's Music  \\\n",
       "103869                  0            0            0                       0   \n",
       "24247                   0            0            0                       0   \n",
       "181919                  0            0            0                       0   \n",
       "152944                  0            0            0                       0   \n",
       "153187                  0            0            0                       0   \n",
       "36711                   0            0            0                       0   \n",
       "124296                  0            0            0                       0   \n",
       "4637                    0            0            0                       0   \n",
       "104698                  0            0            0                       0   \n",
       "23503                   0            0            0                       0   \n",
       "\n",
       "        genre_Children’s Music  genre_Classical  genre_Comedy  genre_Country  \\\n",
       "103869                       1                0             0              0   \n",
       "24247                        0                0             0              0   \n",
       "181919                       0                0             0              0   \n",
       "152944                       0                0             0              0   \n",
       "153187                       0                0             0              0   \n",
       "36711                        0                0             0              0   \n",
       "124296                       0                1             0              0   \n",
       "4637                         0                0             0              1   \n",
       "104698                       0                1             0              0   \n",
       "23503                        0                0             0              0   \n",
       "\n",
       "        genre_Dance  genre_Electronic  genre_Folk  genre_Hip-Hop  genre_Indie  \\\n",
       "103869            0                 0           0              0            0   \n",
       "24247             0                 1           0              0            0   \n",
       "181919            0                 0           0              0            0   \n",
       "152944            0                 0           0              0            0   \n",
       "153187            0                 0           0              0            0   \n",
       "36711             0                 1           0              0            0   \n",
       "124296            0                 0           0              0            0   \n",
       "4637              0                 0           0              0            0   \n",
       "104698            0                 0           0              0            0   \n",
       "23503             0                 1           0              0            0   \n",
       "\n",
       "        genre_Jazz  genre_Movie  genre_OTHER  genre_Opera  genre_Pop  \\\n",
       "103869           0            0            0            0          0   \n",
       "24247            0            0            0            0          0   \n",
       "181919           0            1            0            0          0   \n",
       "152944           0            0            0            0          0   \n",
       "153187           0            0            0            0          0   \n",
       "36711            0            0            0            0          0   \n",
       "124296           0            0            0            0          0   \n",
       "4637             0            0            0            0          0   \n",
       "104698           0            0            0            0          0   \n",
       "23503            0            0            0            0          0   \n",
       "\n",
       "        genre_R&B  genre_Rap  genre_Reggae  genre_Reggaeton  genre_Rock  \\\n",
       "103869          0          0             0                0           0   \n",
       "24247           0          0             0                0           0   \n",
       "181919          0          0             0                0           0   \n",
       "152944          1          0             0                0           0   \n",
       "153187          0          0             0                0           1   \n",
       "36711           0          0             0                0           0   \n",
       "124296          0          0             0                0           0   \n",
       "4637            0          0             0                0           0   \n",
       "104698          0          0             0                0           0   \n",
       "23503           0          0             0                0           0   \n",
       "\n",
       "        genre_Ska  genre_Soul  genre_Soundtrack  genre_World  \\\n",
       "103869          0           0                 0            0   \n",
       "24247           0           0                 0            0   \n",
       "181919          0           0                 0            0   \n",
       "152944          0           0                 0            0   \n",
       "153187          0           0                 0            0   \n",
       "36711           0           0                 0            0   \n",
       "124296          0           0                 0            0   \n",
       "4637            0           0                 0            0   \n",
       "104698          0           0                 0            0   \n",
       "23503           0           0                 0            0   \n",
       "\n",
       "        time_signature_0/4  time_signature_1/4  time_signature_3/4  \\\n",
       "103869                   0                   0                   0   \n",
       "24247                    0                   0                   0   \n",
       "181919                   0                   0                   0   \n",
       "152944                   0                   0                   0   \n",
       "153187                   0                   0                   0   \n",
       "36711                    0                   0                   0   \n",
       "124296                   0                   0                   0   \n",
       "4637                     0                   0                   0   \n",
       "104698                   0                   0                   0   \n",
       "23503                    0                   0                   0   \n",
       "\n",
       "        time_signature_4/4  time_signature_5/4  key_A  key_A#  key_B  key_C  \\\n",
       "103869                   1                   0      0       0      0      0   \n",
       "24247                    1                   0      0       1      0      0   \n",
       "181919                   1                   0      0       0      0      0   \n",
       "152944                   1                   0      0       1      0      0   \n",
       "153187                   1                   0      0       0      0      0   \n",
       "36711                    1                   0      0       0      0      0   \n",
       "124296                   1                   0      0       0      0      1   \n",
       "4637                     1                   0      0       0      0      0   \n",
       "104698                   1                   0      0       0      0      0   \n",
       "23503                    1                   0      0       0      0      0   \n",
       "\n",
       "        key_C#  key_D  key_D#  key_E  key_F  key_F#  key_G  key_G#  \\\n",
       "103869       0      0       0      0      0       0      0       1   \n",
       "24247        0      0       0      0      0       0      0       0   \n",
       "181919       0      0       0      0      0       0      1       0   \n",
       "152944       0      0       0      0      0       0      0       0   \n",
       "153187       0      1       0      0      0       0      0       0   \n",
       "36711        0      0       0      0      0       0      1       0   \n",
       "124296       0      0       0      0      0       0      0       0   \n",
       "4637         0      1       0      0      0       0      0       0   \n",
       "104698       1      0       0      0      0       0      0       0   \n",
       "23503        0      0       0      0      1       0      0       0   \n",
       "\n",
       "        mode_Major  mode_Minor  \n",
       "103869           0           1  \n",
       "24247            0           1  \n",
       "181919           1           0  \n",
       "152944           1           0  \n",
       "153187           0           1  \n",
       "36711            0           1  \n",
       "124296           1           0  \n",
       "4637             1           0  \n",
       "104698           1           0  \n",
       "23503            1           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, columns=[\"genre\", \"time_signature\", \"key\",\"mode\"])\n",
    "pd.set_option(\"max_columns\",None)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we split the data into 60% training 20% validation and 20% test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = np.split(data.sample(frac=1), [int(.6*len(data)), int(.8*len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46545 46545 139635\n"
     ]
    }
   ],
   "source": [
    "print(len(test), len(validate), len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have plenty of rows in the dataset. Before starting a training  session I would like to \n",
    "# make sure that the network is functioning properly.\n",
    "# So let's just play around with a fraction of the dataset, I don't want to lock my computer for hours\n",
    "demo_train = train[:10000]\n",
    "demo_validate = validate[:2000]\n",
    "demo_test = test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove 'demo_' to run the training on the whole dataset.\n",
    "\n",
    "# Let's extract the target column from the dataset.\n",
    "Y_train = demo_train['popularity'].values\n",
    "Y_validate = demo_validate['popularity'].values\n",
    "Y_test = demo_test['popularity'].values\n",
    "\n",
    "# We also create the train, test, and validation input here\n",
    "X_train = demo_train.drop(columns=['popularity'])\n",
    "X_validate = demo_validate.drop(columns=['popularity'])\n",
    "X_test = demo_test.drop(columns=['popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Not all features are standardized so let's do it before we start he training\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_validate = scaler.transform(X_validate)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# importing necessary keras packages\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 40)                2280      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 15)                465       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 3,991\n",
      "Trainable params: 3,991\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=56, units=40)`\n",
      "  import sys\n",
      "/home/daniel/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=30)`\n",
      "  if __name__ == '__main__':\n",
      "/home/daniel/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=15)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/daniel/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#define callbacks\n",
    "patience=30\n",
    "early_stopping=EarlyStopping(patience=patience, verbose=1)\n",
    "checkpointer=ModelCheckpoint(filepath='weights.hdf5', save_best_only=True, verbose=1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim=40, input_dim=X_train.shape[1]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=30))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(output_dim=15))\n",
    "model.add(Activation('relu'))\n",
    "# This a regression problem where we target values in 0-100 range\n",
    "model.add(Dense(output_dim=1, activation='relu'))\n",
    "# Let's have a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/daniel/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 10000 samples, validate on 2000 samples\n",
      "Epoch 1/200\n",
      " - 1s - loss: 2019.7855 - val_loss: 2031.4243\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2031.42433, saving model to weights.hdf5\n",
      "Epoch 2/200\n",
      " - 1s - loss: 2019.3284 - val_loss: 2030.0968\n",
      "\n",
      "Epoch 00002: val_loss improved from 2031.42433 to 2030.09680, saving model to weights.hdf5\n",
      "Epoch 3/200\n",
      " - 1s - loss: 1975.2878 - val_loss: 1803.6781\n",
      "\n",
      "Epoch 00003: val_loss improved from 2030.09680 to 1803.67813, saving model to weights.hdf5\n",
      "Epoch 4/200\n",
      " - 1s - loss: 736.4616 - val_loss: 188.7085\n",
      "\n",
      "Epoch 00004: val_loss improved from 1803.67813 to 188.70845, saving model to weights.hdf5\n",
      "Epoch 5/200\n",
      " - 1s - loss: 150.6487 - val_loss: 123.6564\n",
      "\n",
      "Epoch 00005: val_loss improved from 188.70845 to 123.65637, saving model to weights.hdf5\n",
      "Epoch 6/200\n",
      " - 1s - loss: 120.6651 - val_loss: 108.7864\n",
      "\n",
      "Epoch 00006: val_loss improved from 123.65637 to 108.78640, saving model to weights.hdf5\n",
      "Epoch 7/200\n",
      " - 1s - loss: 111.8462 - val_loss: 103.2076\n",
      "\n",
      "Epoch 00007: val_loss improved from 108.78640 to 103.20763, saving model to weights.hdf5\n",
      "Epoch 8/200\n",
      " - 1s - loss: 107.5418 - val_loss: 100.2723\n",
      "\n",
      "Epoch 00008: val_loss improved from 103.20763 to 100.27225, saving model to weights.hdf5\n",
      "Epoch 9/200\n",
      " - 1s - loss: 104.8672 - val_loss: 98.9825\n",
      "\n",
      "Epoch 00009: val_loss improved from 100.27225 to 98.98253, saving model to weights.hdf5\n",
      "Epoch 10/200\n",
      " - 1s - loss: 103.0103 - val_loss: 97.2378\n",
      "\n",
      "Epoch 00010: val_loss improved from 98.98253 to 97.23783, saving model to weights.hdf5\n",
      "Epoch 11/200\n",
      " - 1s - loss: 101.5435 - val_loss: 96.6586\n",
      "\n",
      "Epoch 00011: val_loss improved from 97.23783 to 96.65860, saving model to weights.hdf5\n",
      "Epoch 12/200\n",
      " - 1s - loss: 100.4266 - val_loss: 95.6984\n",
      "\n",
      "Epoch 00012: val_loss improved from 96.65860 to 95.69843, saving model to weights.hdf5\n",
      "Epoch 13/200\n",
      " - 1s - loss: 99.4746 - val_loss: 95.2679\n",
      "\n",
      "Epoch 00013: val_loss improved from 95.69843 to 95.26787, saving model to weights.hdf5\n",
      "Epoch 14/200\n",
      " - 1s - loss: 98.5754 - val_loss: 94.7577\n",
      "\n",
      "Epoch 00014: val_loss improved from 95.26787 to 94.75767, saving model to weights.hdf5\n",
      "Epoch 15/200\n",
      " - 1s - loss: 97.8630 - val_loss: 94.3169\n",
      "\n",
      "Epoch 00015: val_loss improved from 94.75767 to 94.31694, saving model to weights.hdf5\n",
      "Epoch 16/200\n",
      " - 1s - loss: 97.1193 - val_loss: 94.0061\n",
      "\n",
      "Epoch 00016: val_loss improved from 94.31694 to 94.00609, saving model to weights.hdf5\n",
      "Epoch 17/200\n",
      " - 1s - loss: 96.5777 - val_loss: 94.0471\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 94.00609\n",
      "Epoch 18/200\n",
      " - 1s - loss: 96.0341 - val_loss: 93.5478\n",
      "\n",
      "Epoch 00018: val_loss improved from 94.00609 to 93.54783, saving model to weights.hdf5\n",
      "Epoch 19/200\n",
      " - 1s - loss: 95.5373 - val_loss: 93.3563\n",
      "\n",
      "Epoch 00019: val_loss improved from 93.54783 to 93.35633, saving model to weights.hdf5\n",
      "Epoch 20/200\n",
      " - 1s - loss: 95.0289 - val_loss: 93.0972\n",
      "\n",
      "Epoch 00020: val_loss improved from 93.35633 to 93.09724, saving model to weights.hdf5\n",
      "Epoch 21/200\n",
      " - 1s - loss: 94.5903 - val_loss: 93.0194\n",
      "\n",
      "Epoch 00021: val_loss improved from 93.09724 to 93.01942, saving model to weights.hdf5\n",
      "Epoch 22/200\n",
      " - 1s - loss: 94.1642 - val_loss: 92.7719\n",
      "\n",
      "Epoch 00022: val_loss improved from 93.01942 to 92.77190, saving model to weights.hdf5\n",
      "Epoch 23/200\n",
      " - 1s - loss: 93.8031 - val_loss: 92.6713\n",
      "\n",
      "Epoch 00023: val_loss improved from 92.77190 to 92.67133, saving model to weights.hdf5\n",
      "Epoch 24/200\n",
      " - 1s - loss: 93.4089 - val_loss: 92.4736\n",
      "\n",
      "Epoch 00024: val_loss improved from 92.67133 to 92.47359, saving model to weights.hdf5\n",
      "Epoch 25/200\n",
      " - 1s - loss: 93.0809 - val_loss: 92.5335\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 92.47359\n",
      "Epoch 26/200\n",
      " - 1s - loss: 92.7764 - val_loss: 92.3753\n",
      "\n",
      "Epoch 00026: val_loss improved from 92.47359 to 92.37530, saving model to weights.hdf5\n",
      "Epoch 27/200\n",
      " - 1s - loss: 92.4059 - val_loss: 92.3127\n",
      "\n",
      "Epoch 00027: val_loss improved from 92.37530 to 92.31273, saving model to weights.hdf5\n",
      "Epoch 28/200\n",
      " - 1s - loss: 92.1744 - val_loss: 92.0929\n",
      "\n",
      "Epoch 00028: val_loss improved from 92.31273 to 92.09287, saving model to weights.hdf5\n",
      "Epoch 29/200\n",
      " - 1s - loss: 91.9184 - val_loss: 92.0615\n",
      "\n",
      "Epoch 00029: val_loss improved from 92.09287 to 92.06152, saving model to weights.hdf5\n",
      "Epoch 30/200\n",
      " - 1s - loss: 91.6265 - val_loss: 92.2821\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 92.06152\n",
      "Epoch 31/200\n",
      " - 1s - loss: 91.4074 - val_loss: 91.8924\n",
      "\n",
      "Epoch 00031: val_loss improved from 92.06152 to 91.89244, saving model to weights.hdf5\n",
      "Epoch 32/200\n",
      " - 1s - loss: 91.1313 - val_loss: 92.0311\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 91.89244\n",
      "Epoch 33/200\n",
      " - 1s - loss: 90.9596 - val_loss: 91.6207\n",
      "\n",
      "Epoch 00033: val_loss improved from 91.89244 to 91.62065, saving model to weights.hdf5\n",
      "Epoch 34/200\n",
      " - 1s - loss: 90.7306 - val_loss: 91.7593\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 91.62065\n",
      "Epoch 35/200\n",
      " - 1s - loss: 90.5793 - val_loss: 91.7041\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 91.62065\n",
      "Epoch 36/200\n",
      " - 1s - loss: 90.2820 - val_loss: 91.3873\n",
      "\n",
      "Epoch 00036: val_loss improved from 91.62065 to 91.38731, saving model to weights.hdf5\n",
      "Epoch 37/200\n",
      " - 1s - loss: 90.1722 - val_loss: 91.3480\n",
      "\n",
      "Epoch 00037: val_loss improved from 91.38731 to 91.34799, saving model to weights.hdf5\n",
      "Epoch 38/200\n",
      " - 1s - loss: 90.0273 - val_loss: 91.4344\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 91.34799\n",
      "Epoch 39/200\n",
      " - 1s - loss: 89.8337 - val_loss: 91.5357\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 91.34799\n",
      "Epoch 40/200\n",
      " - 1s - loss: 89.5571 - val_loss: 91.3512\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 91.34799\n",
      "Epoch 41/200\n",
      " - 1s - loss: 89.4876 - val_loss: 91.6879\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 91.34799\n",
      "Epoch 42/200\n",
      " - 1s - loss: 89.3650 - val_loss: 91.2729\n",
      "\n",
      "Epoch 00042: val_loss improved from 91.34799 to 91.27291, saving model to weights.hdf5\n",
      "Epoch 43/200\n",
      " - 1s - loss: 89.1872 - val_loss: 91.2870\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 91.27291\n",
      "Epoch 44/200\n",
      " - 1s - loss: 89.0214 - val_loss: 91.1698\n",
      "\n",
      "Epoch 00044: val_loss improved from 91.27291 to 91.16984, saving model to weights.hdf5\n",
      "Epoch 45/200\n",
      " - 1s - loss: 88.8885 - val_loss: 91.2237\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 91.16984\n",
      "Epoch 46/200\n",
      " - 1s - loss: 88.7380 - val_loss: 91.3181\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 91.16984\n",
      "Epoch 47/200\n",
      " - 1s - loss: 88.6146 - val_loss: 91.1090\n",
      "\n",
      "Epoch 00047: val_loss improved from 91.16984 to 91.10898, saving model to weights.hdf5\n",
      "Epoch 48/200\n",
      " - 1s - loss: 88.4970 - val_loss: 91.4246\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 91.10898\n",
      "Epoch 49/200\n",
      " - 1s - loss: 88.4146 - val_loss: 90.9433\n",
      "\n",
      "Epoch 00049: val_loss improved from 91.10898 to 90.94332, saving model to weights.hdf5\n",
      "Epoch 50/200\n",
      " - 1s - loss: 88.3183 - val_loss: 90.9337\n",
      "\n",
      "Epoch 00050: val_loss improved from 90.94332 to 90.93373, saving model to weights.hdf5\n",
      "Epoch 51/200\n",
      " - 1s - loss: 88.2003 - val_loss: 90.8988\n",
      "\n",
      "Epoch 00051: val_loss improved from 90.93373 to 90.89883, saving model to weights.hdf5\n",
      "Epoch 52/200\n",
      " - 1s - loss: 88.0428 - val_loss: 91.3013\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 90.89883\n",
      "Epoch 53/200\n",
      " - 1s - loss: 87.9910 - val_loss: 90.9038\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 90.89883\n",
      "Epoch 54/200\n",
      " - 1s - loss: 87.8429 - val_loss: 91.0836\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 90.89883\n",
      "Epoch 55/200\n",
      " - 1s - loss: 87.7797 - val_loss: 91.0261\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 90.89883\n",
      "Epoch 56/200\n",
      " - 1s - loss: 87.6973 - val_loss: 91.0048\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 90.89883\n",
      "Epoch 57/200\n",
      " - 0s - loss: 87.6050 - val_loss: 90.9323\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 90.89883\n",
      "Epoch 58/200\n",
      " - 1s - loss: 87.5249 - val_loss: 90.8282\n",
      "\n",
      "Epoch 00058: val_loss improved from 90.89883 to 90.82818, saving model to weights.hdf5\n",
      "Epoch 59/200\n",
      " - 0s - loss: 87.3792 - val_loss: 90.7559\n",
      "\n",
      "Epoch 00059: val_loss improved from 90.82818 to 90.75593, saving model to weights.hdf5\n",
      "Epoch 60/200\n",
      " - 0s - loss: 87.3475 - val_loss: 90.6949\n",
      "\n",
      "Epoch 00060: val_loss improved from 90.75593 to 90.69485, saving model to weights.hdf5\n",
      "Epoch 61/200\n",
      " - 1s - loss: 87.2475 - val_loss: 90.8682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00061: val_loss did not improve from 90.69485\n",
      "Epoch 62/200\n",
      " - 1s - loss: 87.1592 - val_loss: 90.8772\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 90.69485\n",
      "Epoch 63/200\n",
      " - 1s - loss: 87.0992 - val_loss: 90.9173\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 90.69485\n",
      "Epoch 64/200\n",
      " - 1s - loss: 86.9761 - val_loss: 90.7908\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 90.69485\n",
      "Epoch 65/200\n",
      " - 1s - loss: 86.9336 - val_loss: 90.5816\n",
      "\n",
      "Epoch 00065: val_loss improved from 90.69485 to 90.58160, saving model to weights.hdf5\n",
      "Epoch 66/200\n",
      " - 1s - loss: 86.8683 - val_loss: 90.5939\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 90.58160\n",
      "Epoch 67/200\n",
      " - 1s - loss: 86.7809 - val_loss: 90.5381\n",
      "\n",
      "Epoch 00067: val_loss improved from 90.58160 to 90.53808, saving model to weights.hdf5\n",
      "Epoch 68/200\n",
      " - 1s - loss: 86.7028 - val_loss: 90.6596\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 90.53808\n",
      "Epoch 69/200\n",
      " - 1s - loss: 86.6540 - val_loss: 90.6398\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 90.53808\n",
      "Epoch 70/200\n",
      " - 1s - loss: 86.5777 - val_loss: 90.6044\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 90.53808\n",
      "Epoch 71/200\n",
      " - 1s - loss: 86.4910 - val_loss: 90.4360\n",
      "\n",
      "Epoch 00071: val_loss improved from 90.53808 to 90.43603, saving model to weights.hdf5\n",
      "Epoch 72/200\n",
      " - 1s - loss: 86.4318 - val_loss: 90.5756\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 90.43603\n",
      "Epoch 73/200\n",
      " - 1s - loss: 86.4037 - val_loss: 90.5068\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 90.43603\n",
      "Epoch 74/200\n",
      " - 1s - loss: 86.3284 - val_loss: 90.5006\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 90.43603\n",
      "Epoch 75/200\n",
      " - 1s - loss: 86.2715 - val_loss: 90.7165\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 90.43603\n",
      "Epoch 76/200\n",
      " - 1s - loss: 86.1868 - val_loss: 90.4739\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 90.43603\n",
      "Epoch 77/200\n",
      " - 1s - loss: 86.1153 - val_loss: 90.7320\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 90.43603\n",
      "Epoch 78/200\n",
      " - 1s - loss: 86.0637 - val_loss: 90.5193\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 90.43603\n",
      "Epoch 79/200\n",
      " - 1s - loss: 85.9763 - val_loss: 90.5265\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 90.43603\n",
      "Epoch 80/200\n",
      " - 1s - loss: 85.9133 - val_loss: 90.4452\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 90.43603\n",
      "Epoch 81/200\n",
      " - 1s - loss: 85.8946 - val_loss: 90.4670\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 90.43603\n",
      "Epoch 82/200\n",
      " - 1s - loss: 85.8796 - val_loss: 90.5426\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 90.43603\n",
      "Epoch 83/200\n",
      " - 1s - loss: 85.7178 - val_loss: 90.6655\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 90.43603\n",
      "Epoch 84/200\n",
      " - 1s - loss: 85.7572 - val_loss: 90.3735\n",
      "\n",
      "Epoch 00084: val_loss improved from 90.43603 to 90.37352, saving model to weights.hdf5\n",
      "Epoch 85/200\n",
      " - 1s - loss: 85.6189 - val_loss: 90.5420\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 90.37352\n",
      "Epoch 86/200\n",
      " - 1s - loss: 85.6158 - val_loss: 90.5149\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 90.37352\n",
      "Epoch 87/200\n",
      " - 1s - loss: 85.5441 - val_loss: 90.3859\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 90.37352\n",
      "Epoch 88/200\n",
      " - 1s - loss: 85.4754 - val_loss: 90.4987\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 90.37352\n",
      "Epoch 89/200\n",
      " - 1s - loss: 85.4520 - val_loss: 90.3602\n",
      "\n",
      "Epoch 00089: val_loss improved from 90.37352 to 90.36016, saving model to weights.hdf5\n",
      "Epoch 90/200\n",
      " - 1s - loss: 85.3957 - val_loss: 90.4739\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 90.36016\n",
      "Epoch 91/200\n",
      " - 1s - loss: 85.3533 - val_loss: 90.4638\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 90.36016\n",
      "Epoch 92/200\n",
      " - 1s - loss: 85.2448 - val_loss: 90.2738\n",
      "\n",
      "Epoch 00092: val_loss improved from 90.36016 to 90.27382, saving model to weights.hdf5\n",
      "Epoch 93/200\n",
      " - 1s - loss: 85.2584 - val_loss: 90.4155\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 90.27382\n",
      "Epoch 94/200\n",
      " - 1s - loss: 85.2041 - val_loss: 90.4724\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 90.27382\n",
      "Epoch 95/200\n",
      " - 1s - loss: 85.1541 - val_loss: 90.4471\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 90.27382\n",
      "Epoch 96/200\n",
      " - 1s - loss: 85.1013 - val_loss: 90.6833\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 90.27382\n",
      "Epoch 97/200\n",
      " - 1s - loss: 85.0929 - val_loss: 90.3905\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 90.27382\n",
      "Epoch 98/200\n",
      " - 1s - loss: 85.0275 - val_loss: 90.5272\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 90.27382\n",
      "Epoch 99/200\n",
      " - 1s - loss: 85.0043 - val_loss: 90.3468\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 90.27382\n",
      "Epoch 100/200\n",
      " - 1s - loss: 84.9530 - val_loss: 90.5138\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 90.27382\n",
      "Epoch 101/200\n",
      " - 1s - loss: 84.8791 - val_loss: 90.4703\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 90.27382\n",
      "Epoch 102/200\n",
      " - 1s - loss: 84.8531 - val_loss: 90.4435\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 90.27382\n",
      "Epoch 103/200\n",
      " - 1s - loss: 84.8009 - val_loss: 90.5329\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 90.27382\n",
      "Epoch 104/200\n",
      " - 1s - loss: 84.7514 - val_loss: 90.3684\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 90.27382\n",
      "Epoch 105/200\n",
      " - 1s - loss: 84.6976 - val_loss: 90.3654\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 90.27382\n",
      "Epoch 106/200\n",
      " - 1s - loss: 84.6757 - val_loss: 90.5957\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 90.27382\n",
      "Epoch 107/200\n",
      " - 1s - loss: 84.6457 - val_loss: 90.4246\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 90.27382\n",
      "Epoch 108/200\n",
      " - 1s - loss: 84.6055 - val_loss: 90.5277\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 90.27382\n",
      "Epoch 109/200\n",
      " - 1s - loss: 84.5567 - val_loss: 90.4792\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 90.27382\n",
      "Epoch 110/200\n",
      " - 1s - loss: 84.5305 - val_loss: 90.6145\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 90.27382\n",
      "Epoch 111/200\n",
      " - 1s - loss: 84.4607 - val_loss: 90.3775\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 90.27382\n",
      "Epoch 112/200\n",
      " - 1s - loss: 84.4302 - val_loss: 90.4698\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 90.27382\n",
      "Epoch 113/200\n",
      " - 1s - loss: 84.3823 - val_loss: 90.5941\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 90.27382\n",
      "Epoch 114/200\n",
      " - 1s - loss: 84.3572 - val_loss: 90.7342\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 90.27382\n",
      "Epoch 115/200\n",
      " - 1s - loss: 84.3214 - val_loss: 90.5061\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 90.27382\n",
      "Epoch 116/200\n",
      " - 1s - loss: 84.2858 - val_loss: 90.4875\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 90.27382\n",
      "Epoch 117/200\n",
      " - 1s - loss: 84.2366 - val_loss: 90.4717\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 90.27382\n",
      "Epoch 118/200\n",
      " - 1s - loss: 84.1883 - val_loss: 90.3898\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 90.27382\n",
      "Epoch 119/200\n",
      " - 1s - loss: 84.1770 - val_loss: 90.6655\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 90.27382\n",
      "Epoch 120/200\n",
      " - 1s - loss: 84.1420 - val_loss: 90.4443\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 90.27382\n",
      "Epoch 121/200\n",
      " - 1s - loss: 84.0925 - val_loss: 90.3882\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 90.27382\n",
      "Epoch 122/200\n",
      " - 1s - loss: 83.9913 - val_loss: 90.7993\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 90.27382\n",
      "Epoch 00122: early stopping\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.00001)\n",
    "# using mse for regression problem\n",
    "model.compile(loss='mse', optimizer=sgd)\n",
    "history=model.fit(X_train,Y_train,epochs=200, \n",
    "                  batch_size=16,\n",
    "                  verbose=2,\n",
    "                  validation_data=(X_validate, Y_validate),\n",
    "                  callbacks=[checkpointer, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error:  100.00394219449768\n"
     ]
    }
   ],
   "source": [
    "# Load the weights that performed best on the validation dataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model = load_model('weights.hdf5')\n",
    "# predictions for the test dataset\n",
    "preds = model.predict(X_test)\n",
    "test_err = mean_squared_error(Y_test, preds)\n",
    "print(\"Test error: \",test_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training only on a sample dataset gave us 100 error on the test dataset. This means that model's predictions miss the correct value by 10 on average. So far not the best result, but still it shows some correspondence between the features and the popularity. Next step is to start investigating what effect the lyrics have on a track's popularity using NLP."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
